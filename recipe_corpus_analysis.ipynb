{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f4a7d4e-248f-4614-ab84-35eebbfb4bee",
   "metadata": {},
   "source": [
    "Assignment 1 - NLTK and corpus functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e82eaff-a9e1-42ca-9745-eddf445edde0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee5c74e-1b19-4d18-85d2-c3dad109e8aa",
   "metadata": {},
   "source": [
    "Subcorpus for Recipe (Takaya Shirai)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25772d5a-5bd2-4512-b25b-2119e7544335",
   "metadata": {},
   "source": [
    "0. Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ad42f2f4-c53a-4d19-9464-ebf74e8d2acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing libraries\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7ae5cb44-30ea-4ea7-92bc-0143d17fdbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the recipe corpus from the data directory\n",
    "corpus_root = \"./data\"\n",
    "reviews = PlaintextCorpusReader(corpus_root, '.*')\n",
    "recipe_corpus = reviews.words('recipe.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7decd83b-5445-4a60-ad7f-7c4f7bde0bc7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274505b6-819f-4cde-9085-b44bd22ac49d",
   "metadata": {},
   "source": [
    "1. The length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "42a5f9b8-bca3-482f-a389-93d214b87758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original corpus length: 8747\n",
      "Alphabet-only and lower-cased corpus length: 7093\n"
     ]
    }
   ],
   "source": [
    "## Calculate the length of the original recipe corpus\n",
    "recipe_corpus_len = len(recipe_corpus)\n",
    "print(f\"Original corpus length: {recipe_corpus_len}\")\n",
    "\n",
    "## Create a corpus containing only alphabetic words and convert them to lowercase\n",
    "recipe_alpha_corpus = [word.lower() for word in recipe_corpus if word.isalpha()]\n",
    "recipe_alpha_corpus_len = len(recipe_alpha_corpus)\n",
    "print(f\"Alphabet-only and lower-cased corpus length: {recipe_alpha_corpus_len}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ff8657-a08a-4aa4-9bfe-9bf05ffa5b73",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca43b0e-c96f-4726-93fe-82d704c294f8",
   "metadata": {},
   "source": [
    "2. The lexical diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1cee32b7-e765-48cf-9ea9-dbb35871359f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function for calculating the lexical diversity of a text\n",
    "def lexical_diversity(text):\n",
    "    sorted_words = sorted(w.lower() for w in text)\n",
    "    unique_sorted_words = sorted(set(w.lower() for w in text))\n",
    "    return len(set(unique_sorted_words)) / len(sorted_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fccb83eb-1b23-465c-9dfc-095ea0994976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lexical diversity for the recipe corpus: 0.18029038527495142\n",
      "lexical diversity for the alphabet only recipe corpus: 0.210630198787537\n"
     ]
    }
   ],
   "source": [
    "## Print the lexical diversities\n",
    "print(f\"lexical diversity for the recipe corpus: {lexical_diversity(recipe_corpus)}\")\n",
    "print(f\"lexical diversity for the alphabet only recipe corpus: {lexical_diversity(recipe_alpha_corpus)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defb566e-2b41-4378-bcc8-95985cfd637a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41c9be0-a9cb-45f0-aeaa-a404abbff7ea",
   "metadata": {},
   "source": [
    "3. Top 10 most frequent words and their counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "238c7045-80a5-42e2-82a6-948ea6396fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the frequency distributions for the original and alphabet-only recipe corpora\n",
    "freq_dist = FreqDist(recipe_corpus)\n",
    "freq_dist_alpha = FreqDist(recipe_alpha_corpus)\n",
    "\n",
    "## Store the 10 most frequent words from each frequency distribution\n",
    "most_freq_words = freq_dist.most_common(10)\n",
    "most_freq_words_alpha = freq_dist_alpha.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e8eaa7c4-5d06-452b-9126-69b54e655c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 most frequent words in the original recipe corpus:\n",
      "word: '.', count: 379\n",
      "word: ',', count: 345\n",
      "word: 'the', count: 334\n",
      "word: 'and', count: 199\n",
      "word: 'a', count: 172\n",
      "word: 'to', count: 157\n",
      "word: 'in', count: 114\n",
      "word: 'of', count: 112\n",
      "word: 'â€™', count: 107\n",
      "word: 'it', count: 105\n",
      "\n",
      "10 most frequent words in the alphabet-only recipe corpus:\n",
      "word: 'the', count: 351\n",
      "word: 'and', count: 206\n",
      "word: 'a', count: 176\n",
      "word: 'to', count: 166\n",
      "word: 'in', count: 125\n",
      "word: 'it', count: 117\n",
      "word: 'of', count: 112\n",
      "word: 'for', count: 92\n",
      "word: 'with', count: 89\n",
      "word: 'is', count: 76\n"
     ]
    }
   ],
   "source": [
    "## Print the 10 most frequent words\n",
    "print(\"10 most frequent words in the original recipe corpus:\")\n",
    "for word, count in most_freq_words:\n",
    "    print(f\"word: '{word}', count: {count}\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"10 most frequent words in the alphabet-only recipe corpus:\")\n",
    "for word, count in most_freq_words_alpha:\n",
    "    print(f\"word: '{word}', count: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dd5baa-82fb-4782-ad0d-9199bad38ee3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ecf4f6-2c62-4c8d-9b66-75b3856bf2bc",
   "metadata": {},
   "source": [
    "4. Words that are at least 10 characters long and their counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e45a77c8-4b5f-490b-bf20-9cbeda628491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words that are at least 10 characters long in the original recipe corpus:\n",
      "word: 'cranberries', count: 3\n",
      "word: 'pistachios', count: 3\n",
      "word: 'Ingredients', count: 9\n",
      "word: 'tablespoons', count: 12\n",
      "word: 'tablespoon', count: 4\n",
      "word: 'ingredients', count: 18\n",
      "word: 'Directions', count: 7\n",
      "word: 'vegetables', count: 6\n",
      "word: 'overlapping', count: 1\n",
      "word: 'Alternatives', count: 2\n",
      "word: 'breadcrumbs', count: 7\n",
      "word: 'separately', count: 1\n",
      "word: 'beforehand', count: 1\n",
      "word: 'breadcrumb', count: 1\n",
      "word: 'Worcestershire', count: 2\n",
      "word: 'Substitute', count: 3\n",
      "word: 'wholegrain', count: 1\n",
      "word: 'portobello', count: 1\n",
      "word: 'substitute', count: 3\n",
      "word: 'throughout', count: 3\n",
      "word: 'reasonably', count: 1\n",
      "word: 'traditional', count: 2\n",
      "word: 'Bourguignon', count: 1\n",
      "word: 'cauliflower', count: 1\n",
      "word: 'Vietnamese', count: 1\n",
      "word: 'caramelise', count: 1\n",
      "word: 'lemongrass', count: 2\n",
      "word: 'incredible', count: 1\n",
      "word: 'difference', count: 2\n",
      "word: 'reputation', count: 1\n",
      "word: 'overcooked', count: 2\n",
      "word: 'flavourless', count: 1\n",
      "word: 'sophisticated', count: 1\n",
      "word: 'supermarkets', count: 2\n",
      "word: 'Caramelisation', count: 1\n",
      "word: 'suspiciously', count: 1\n",
      "word: 'exaggerating', count: 1\n",
      "word: 'disappointed', count: 1\n",
      "word: 'fundamental', count: 1\n",
      "word: 'Caramelise', count: 1\n",
      "word: 'vermicelli', count: 1\n",
      "word: 'centrepiece', count: 1\n",
      "word: 'caramelisation', count: 3\n",
      "word: 'intensifies', count: 1\n",
      "word: 'caramelises', count: 1\n",
      "word: 'beautifully', count: 1\n",
      "word: 'Ingredient', count: 1\n",
      "word: 'absolutely', count: 2\n",
      "word: 'unceremoniously', count: 1\n",
      "word: 'caramelising', count: 1\n",
      "word: 'completely', count: 3\n",
      "word: 'sprinkling', count: 2\n",
      "word: 'presentation', count: 3\n",
      "word: 'deliciousness', count: 1\n",
      "word: 'relatively', count: 1\n",
      "word: 'scattering', count: 1\n",
      "word: 'tenderised', count: 2\n",
      "word: 'economical', count: 3\n",
      "word: 'recipients', count: 1\n",
      "word: 'caramelised', count: 4\n",
      "word: 'marinating', count: 6\n",
      "word: 'restaurant', count: 2\n",
      "word: 'rectangles', count: 3\n",
      "word: 'tenderising', count: 2\n",
      "word: 'Porterhouse', count: 1\n",
      "word: 'ingredient', count: 1\n",
      "word: 'information', count: 1\n",
      "word: 'vegetarian', count: 1\n",
      "word: 'iterations', count: 1\n",
      "word: 'everything', count: 1\n",
      "word: 'recommended', count: 2\n",
      "word: 'porterhouse', count: 1\n",
      "word: 'tenderloin', count: 1\n",
      "word: 'substituted', count: 1\n",
      "word: 'description', count: 1\n",
      "word: 'substitutions', count: 1\n",
      "word: 'intentionally', count: 1\n",
      "word: 'deliberately', count: 1\n",
      "word: 'kaleidoscope', count: 1\n",
      "word: 'alternative', count: 1\n",
      "word: 'MARINATING', count: 1\n",
      "word: 'penetrates', count: 1\n",
      "word: 'INGREDIENTS', count: 1\n",
      "word: 'frequently', count: 1\n",
      "word: 'Caramelised', count: 1\n",
      "word: 'transferring', count: 1\n",
      "word: 'considered', count: 1\n",
      "word: 'interesting', count: 1\n",
      "word: 'granulated', count: 2\n",
      "word: 'temperature', count: 5\n",
      "word: 'thoroughly', count: 1\n",
      "word: 'incorporated', count: 1\n",
      "word: 'generously', count: 1\n",
      "word: 'Alternatively', count: 1\n",
      "word: 'refrigerate', count: 1\n",
      "word: 'casseroles', count: 3\n",
      "word: 'attachment', count: 2\n",
      "word: 'lengthwise', count: 1\n",
      "word: 'substantial', count: 1\n",
      "word: 'Frequently', count: 1\n",
      "word: 'combination', count: 3\n",
      "word: 'thermometer', count: 2\n",
      "word: 'overcooking', count: 1\n",
      "word: 'refrigerator', count: 2\n",
      "word: 'moderately', count: 1\n",
      "word: 'occasionally', count: 1\n",
      "word: 'additional', count: 1\n",
      "\n",
      "Words that are at least 10 characters long in the alphabet-only recipe corpus:\n",
      "word: 'cranberries', count: 3\n",
      "word: 'pistachios', count: 3\n",
      "word: 'ingredients', count: 28\n",
      "word: 'tablespoons', count: 12\n",
      "word: 'tablespoon', count: 4\n",
      "word: 'directions', count: 7\n",
      "word: 'vegetables', count: 6\n",
      "word: 'overlapping', count: 1\n",
      "word: 'alternatives', count: 2\n",
      "word: 'breadcrumbs', count: 7\n",
      "word: 'separately', count: 1\n",
      "word: 'beforehand', count: 1\n",
      "word: 'breadcrumb', count: 1\n",
      "word: 'worcestershire', count: 2\n",
      "word: 'substitute', count: 6\n",
      "word: 'wholegrain', count: 1\n",
      "word: 'portobello', count: 1\n",
      "word: 'throughout', count: 3\n",
      "word: 'reasonably', count: 1\n",
      "word: 'traditional', count: 2\n",
      "word: 'bourguignon', count: 1\n",
      "word: 'cauliflower', count: 1\n",
      "word: 'vietnamese', count: 1\n",
      "word: 'caramelise', count: 2\n",
      "word: 'lemongrass', count: 2\n",
      "word: 'incredible', count: 1\n",
      "word: 'difference', count: 2\n",
      "word: 'reputation', count: 1\n",
      "word: 'overcooked', count: 2\n",
      "word: 'flavourless', count: 1\n",
      "word: 'sophisticated', count: 1\n",
      "word: 'supermarkets', count: 2\n",
      "word: 'caramelisation', count: 4\n",
      "word: 'suspiciously', count: 1\n",
      "word: 'exaggerating', count: 1\n",
      "word: 'disappointed', count: 1\n",
      "word: 'fundamental', count: 1\n",
      "word: 'vermicelli', count: 1\n",
      "word: 'centrepiece', count: 1\n",
      "word: 'intensifies', count: 1\n",
      "word: 'caramelises', count: 1\n",
      "word: 'beautifully', count: 1\n",
      "word: 'ingredient', count: 2\n",
      "word: 'absolutely', count: 2\n",
      "word: 'unceremoniously', count: 1\n",
      "word: 'caramelising', count: 1\n",
      "word: 'completely', count: 3\n",
      "word: 'sprinkling', count: 2\n",
      "word: 'presentation', count: 3\n",
      "word: 'deliciousness', count: 1\n",
      "word: 'relatively', count: 1\n",
      "word: 'scattering', count: 1\n",
      "word: 'tenderised', count: 2\n",
      "word: 'economical', count: 3\n",
      "word: 'recipients', count: 1\n",
      "word: 'caramelised', count: 5\n",
      "word: 'marinating', count: 7\n",
      "word: 'restaurant', count: 2\n",
      "word: 'rectangles', count: 3\n",
      "word: 'tenderising', count: 2\n",
      "word: 'porterhouse', count: 2\n",
      "word: 'information', count: 1\n",
      "word: 'vegetarian', count: 1\n",
      "word: 'iterations', count: 1\n",
      "word: 'everything', count: 1\n",
      "word: 'recommended', count: 2\n",
      "word: 'tenderloin', count: 1\n",
      "word: 'substituted', count: 1\n",
      "word: 'description', count: 1\n",
      "word: 'substitutions', count: 1\n",
      "word: 'intentionally', count: 1\n",
      "word: 'deliberately', count: 1\n",
      "word: 'kaleidoscope', count: 1\n",
      "word: 'alternative', count: 1\n",
      "word: 'penetrates', count: 1\n",
      "word: 'frequently', count: 2\n",
      "word: 'transferring', count: 1\n",
      "word: 'considered', count: 1\n",
      "word: 'interesting', count: 1\n",
      "word: 'granulated', count: 2\n",
      "word: 'temperature', count: 5\n",
      "word: 'thoroughly', count: 1\n",
      "word: 'incorporated', count: 1\n",
      "word: 'generously', count: 1\n",
      "word: 'alternatively', count: 1\n",
      "word: 'refrigerate', count: 1\n",
      "word: 'casseroles', count: 3\n",
      "word: 'attachment', count: 2\n",
      "word: 'lengthwise', count: 1\n",
      "word: 'substantial', count: 1\n",
      "word: 'combination', count: 3\n",
      "word: 'thermometer', count: 2\n",
      "word: 'overcooking', count: 1\n",
      "word: 'refrigerator', count: 2\n",
      "word: 'moderately', count: 1\n",
      "word: 'occasionally', count: 1\n",
      "word: 'additional', count: 1\n"
     ]
    }
   ],
   "source": [
    "## Store the words and their counts that are at least 10 characters long\n",
    "long_words_with_counts = [(word, count) for word, count in freq_dist.items() if len(word) >= 10]\n",
    "long_alpha_words_with_counts = [(word, count) for word, count in freq_dist_alpha.items() if len(word) >= 10]\n",
    "\n",
    "## Print the words that are at least 10 characters long and their counts\n",
    "print(\"Words that are at least 10 characters long in the original recipe corpus:\")\n",
    "for word, count in long_words_with_counts:\n",
    "    print(f\"word: '{word}', count: {count}\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Words that are at least 10 characters long in the alphabet-only recipe corpus:\")\n",
    "for word, count in long_alpha_words_with_counts:\n",
    "    print(f\"word: '{word}', count: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea1e9b5-c1d7-4fea-8845-76ce7cc36906",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481c056c-4f02-420d-ad65-f53e98ca7bd2",
   "metadata": {},
   "source": [
    "5. The longest sentence (type the sentence and give the number of words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f7f4bcb1-56f6-47ef-9f01-6b05f3ceb6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longest sentence:\n",
      "The texture of tenderised slow cooking cuts of beef is not quite the same as steak cuts , but it is still soft and tender , many of them have excellent beefy flavour ( like short rib ) and I would not hesitate to use any of them if that â€™ s all I had !\n",
      "\n",
      "number of words: 56\n"
     ]
    }
   ],
   "source": [
    "## Retrieve the sentences from the recipe corpus\n",
    "recipe_sentences = reviews.sents('recipe.txt')\n",
    "\n",
    "## Find the longest sentence\n",
    "longest_sentence = []\n",
    "for sentence in recipe_sentences:\n",
    "    if len(longest_sentence) < len(sentence):\n",
    "        longest_sentence = sentence \n",
    "\n",
    "## Join the words of the longest sentence into a single string for printing\n",
    "joined_longest_sentence = ' '.join(longest_sentence)\n",
    "\n",
    "## Print the longest sentence along with the word count\n",
    "print(f\"longest sentence:\\n{joined_longest_sentence}\")\n",
    "print()\n",
    "print(f\"number of words: {len(longest_sentence)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c483f7-f8dc-4beb-b310-a916fcc39852",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53964c29-81b5-46d1-8452-d0b31c9d22a1",
   "metadata": {},
   "source": [
    "6. A stemmed version of the longest sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4a9e4259-ee1f-4176-941e-360135888c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "porter stemmed longest sentence:\n",
      "the textur of tenderis slow cook cut of beef is not quit the same as steak cut , but it is still soft and tender , mani of them have excel beefi flavour ( like short rib ) and i would not hesit to use ani of them if that â€™ s all i had !\n",
      "\n",
      "lancaster stemmed longest sentence:\n",
      "the text of tend slow cook cut of beef is not quit the sam as steak cut , but it is stil soft and tend , many of them hav excel beefy flavo ( lik short rib ) and i would not hesit to us any of them if that â€™ s al i had !\n"
     ]
    }
   ],
   "source": [
    "## Initialize the stemmers\n",
    "porter_stemmer = PorterStemmer()\n",
    "lancaster_stemmer = LancasterStemmer()\n",
    "\n",
    "## Stem the words of the longest sentence using both stemmers\n",
    "port_stemmed_sentence = []\n",
    "lanc_stemmed_sentence = []\n",
    "for word in longest_sentence:\n",
    "    port_stemmed_sentence.append(porter_stemmer.stem(word))\n",
    "    lanc_stemmed_sentence.append(lancaster_stemmer.stem(word))\n",
    "\n",
    "## Join the stemmed words into single strings for printing\n",
    "joined_port_stemmed_sentence = ' '.join(port_stemmed_sentence)\n",
    "joined_lanc_stemmed_sentence = ' '.join(lanc_stemmed_sentence)\n",
    "\n",
    "## Print the both stemmed longest sentences\n",
    "print(f\"porter stemmed longest sentence:\\n{joined_port_stemmed_sentence}\")\n",
    "print()\n",
    "print(f\"lancaster stemmed longest sentence:\\n{joined_lanc_stemmed_sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93e4255-82b3-4498-afd3-62b6e4a0c1a9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb2a701-f75c-4abd-b467-5b63bb448268",
   "metadata": {},
   "source": [
    "7. Overall (not for each subcorpus): A reflection (1 paragraph or so): What do the\n",
    "most frequent words, the longest words, and longest sentence tell you about each\n",
    "of the 3 genres? How do you interpret the lexical diversity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896f3fc5-acb4-4024-8eb5-27e2b234a666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc8f7034-36ef-413b-b7ce-2b2840c87f67",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6e3ed8-30c7-4df5-962e-e0130ccf783e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
